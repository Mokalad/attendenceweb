
import streamlit as st
import pandas as pd
import pdfplumber
from docx import Document
from datetime import datetime, timedelta
from io import BytesIO
import calendar

def is_morning_shift(arrival_time):
    return 9 <= arrival_time.hour < 14

def is_evening_shift(arrival_time):
    return arrival_time.hour >= 14

def is_double_shift(arrival_time, departure_time):
    return arrival_time.hour < 14 and departure_time.hour >= 22

def is_single_punch_shift(punch_times):
    return len(punch_times) == 1

def count_shifts(shift_type):
    if shift_type in ['Ù…Ø³Ø§Ø¦ÙŠØ©', 'ØµØ¨Ø§Ø­ÙŠØ©', 'Ø¨ØµÙ…Ø© ÙˆØ§Ø­Ø¯Ø©']:
        return 1
    elif shift_type == 'Ù…Ø²Ø¯ÙˆØ¬Ø©':
        return 2
    return 0

def calculate_overtime(total_shifts):
    return total_shifts - 26 if total_shifts > 26 else 0

def count_delays(punch_times):
    delays = [p for p in punch_times if (p.hour == 15 and p.minute > 10) or (p.hour == 16 and p.minute < 60)]
    return len(delays), delays

arabic_to_english_map = str.maketrans('Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©','0123456789')
def convert_arabic_numerals(text):
    if isinstance(text, str):
        return text.translate(arabic_to_english_map)
    return text

def format_time_12h(time_obj):
    return time_obj.strftime("%I:%M %p")

def load_pdf_data(pdf_file):
    data = []
    with pdfplumber.open(pdf_file) as pdf:
        for page in pdf.pages:
            table = page.extract_table()
            if table and len(table) > 1:
                data.extend(table[1:])
    return data

def process_attendance_data(data):
    df = pd.DataFrame(data, columns=["Ø±Ù‚Ù… Ø§Ù„Ø¨ØµÙ…Ù‡", "Ø§Ù„Ø¥Ø³Ù…", "Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª"])
    df['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª_cleaned'] = df['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª'].apply(convert_arabic_numerals)
    df['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª_final'] = df['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª_cleaned'].astype(str).str.replace('Ù…', 'PM').str.replace('Øµ', 'AM')
    df['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª'] = pd.to_datetime(df['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª_final'], format="%d/%m/%Y %I:%M %p", errors='coerce')
    df.dropna(subset=['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª'], inplace=True)

    if df.empty:
        return pd.DataFrame()

    min_date = df['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª'].min().date()
    max_date = df['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª'].max().date()
    all_dates_in_period = [min_date + timedelta(days=x) for x in range((max_date - min_date).days + 1)]

    summary = []

    for name, group in df.groupby("Ø§Ù„Ø¥Ø³Ù…"):
        group = group.sort_values('Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª')
        shifts_count = 0
        delays_count = 0
        shift_types = set()
        delay_details = []
        morning_shift_details = []
        late_departure_details = []
        attended_dates = set()
        double_shift_details = []

        for day, punches in group.groupby(group['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª'].dt.date):
            attended_dates.add(day)
            punch_times = punches['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª'].tolist()
            arrival = min(punch_times)
            departure = max(punch_times)

            shift_type = None
            if is_single_punch_shift(punch_times):
                shift_type = 'Ø¨ØµÙ…Ø© ÙˆØ§Ø­Ø¯Ø©'
            elif is_double_shift(arrival, departure):
                shift_type = 'Ù…Ø²Ø¯ÙˆØ¬Ø©'
                duration = departure - arrival
                double_shift_details.append([str(day), format_time_12h(arrival), format_time_12h(departure), str(duration)])
            elif is_morning_shift(arrival):
                shift_type = 'ØµØ¨Ø§Ø­ÙŠØ©'
                morning_shift_details.append([str(day), format_time_12h(arrival), format_time_12h(departure)])
            elif is_evening_shift(arrival):
                shift_type = 'Ù…Ø³Ø§Ø¦ÙŠØ©'

            if shift_type:
                shifts_count += count_shifts(shift_type)
                shift_types.add(shift_type)

            daily_delays, delay_times_list = count_delays(punch_times)
            delays_count += daily_delays
            for delay_time in delay_times_list:
                delay_details.append([str(day), format_time_12h(delay_time)])

            if departure.hour > 22 or (departure.hour == 22 and departure.minute >= 20):
                late_departure_details.append([str(day), format_time_12h(departure)])

        overtime_count = calculate_overtime(shifts_count)
        absent_days = sorted([d for d in all_dates_in_period if d not in attended_dates])
        absent_days_formatted = [[f"{day.strftime('%Y-%m-%d')} ({calendar.day_name[day.weekday()]})"] for day in absent_days]

        summary.append({
            "Ø§Ù„Ø¥Ø³Ù…": name,
            "Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª": shifts_count,
            "Ù†ÙˆØ¹ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª": ', '.join(shift_types) if shift_types else 'Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ±Ø¯ÙŠØ§Øª',
            "Ø¹Ø¯Ø¯ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª": delays_count,
            "ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª": delay_details,
            "Ø£ÙŠØ§Ù… Ø§Ù„ØºÙŠØ§Ø¨": len(absent_days),
            "ØªÙØ§ØµÙŠÙ„ Ø£ÙŠØ§Ù… Ø§Ù„ØºÙŠØ§Ø¨": absent_days_formatted,
            "Ø§Ù„Ø¯ÙˆØ§Ù… Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ": overtime_count,
            "ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„ØµØ¨Ø§Ø­ÙŠØ©": morning_shift_details,
            "ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„Ù…ØªØ£Ø®Ø±": late_departure_details,
            "ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©": double_shift_details
        })

    return pd.DataFrame(summary)

def export_to_word(summary_df):
    doc = Document()
    doc.add_heading("ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø­Ø¶ÙˆØ± ÙˆØ§Ù„Ø§Ù†ØµØ±Ø§Ù Ø§Ù„Ø¹Ø§Ù…", level=0)
    doc.add_paragraph("---")
    for index, row in summary_df.iterrows():
        doc.add_heading(f"Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¸Ù: {row['Ø§Ù„Ø¥Ø³Ù…']}", level=1)
        summary_paragraph = doc.add_paragraph()
        summary_paragraph.add_run(
            f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª: {row['Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª']}, "
            f"Ø£Ù†ÙˆØ§Ø¹Ù‡Ø§: {row['Ù†ÙˆØ¹ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª']}, "
            f"ØªØ£Ø®ÙŠØ±Ø§Øª: {row['Ø¹Ø¯Ø¯ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª']}, "
            f"ØºÙŠØ§Ø¨: {row['Ø£ÙŠØ§Ù… Ø§Ù„ØºÙŠØ§Ø¨']}, "
            f"Ø¯ÙˆØ§Ù… Ø¥Ø¶Ø§ÙÙŠ: {row['Ø§Ù„Ø¯ÙˆØ§Ù… Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ']} ÙˆØ±Ø¯ÙŠØ©"
        )
        doc.add_paragraph()

        if row["ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©"]:
            doc.add_paragraph("ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©:")
            table = doc.add_table(rows=1, cols=4)
            table.style = 'Table Grid'
            hdr_cells = table.rows[0].cells
            hdr_cells[0].text = "Ø§Ù„ØªØ§Ø±ÙŠØ®"
            hdr_cells[1].text = "Ø§Ù„Ø­Ø¶ÙˆØ±"
            hdr_cells[2].text = "Ø§Ù„Ø§Ù†ØµØ±Ø§Ù"
            hdr_cells[3].text = "Ø§Ù„Ù…Ø¯Ø©"
            for d in row["ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©"]:
                row_cells = table.add_row().cells
            for i in range(len(d)):
                row_cells[i].text = str(d[i])
            doc.add_paragraph()

        if row["ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„ØµØ¨Ø§Ø­ÙŠØ©"]:
            doc.add_paragraph("Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„ØµØ¨Ø§Ø­ÙŠØ©:")
            table = doc.add_table(rows=1, cols=3)
            table.style = 'Table Grid'
            hdr_cells = table.rows[0].cells
            hdr_cells[0].text = "Ø§Ù„ØªØ§Ø±ÙŠØ®"
            hdr_cells[1].text = "Ø§Ù„Ø­Ø¶ÙˆØ±"
            hdr_cells[2].text = "Ø§Ù„Ø§Ù†ØµØ±Ø§Ù"
            for d in row["ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„ØµØ¨Ø§Ø­ÙŠØ©"]:
                row_cells = table.add_row().cells
            for i in range(len(d)):
                row_cells[i].text = str(d[i])
            doc.add_paragraph()

        if row["ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª"]:
            doc.add_paragraph("ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª:")
            table = doc.add_table(rows=1, cols=2)
            table.style = 'Table Grid'
            hdr_cells = table.rows[0].cells
            hdr_cells[0].text = "Ø§Ù„ØªØ§Ø±ÙŠØ®"
            hdr_cells[1].text = "ÙˆÙ‚Øª Ø§Ù„ØªØ£Ø®ÙŠØ±"
            for d in row["ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª"]:
                row_cells = table.add_row().cells
            for i in range(len(d)):
                row_cells[i].text = str(d[i])
            doc.add_paragraph()

        if row["ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„Ù…ØªØ£Ø®Ø±"]:
            doc.add_paragraph("Ø§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„Ù…ØªØ£Ø®Ø±:")
            table = doc.add_table(rows=1, cols=2)
            table.style = 'Table Grid'
            hdr_cells = table.rows[0].cells
            hdr_cells[0].text = "Ø§Ù„ØªØ§Ø±ÙŠØ®"
            hdr_cells[1].text = "ÙˆÙ‚Øª Ø§Ù„Ø®Ø±ÙˆØ¬"
            for d in row["ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„Ù…ØªØ£Ø®Ø±"]:
                row_cells = table.add_row().cells
            for i in range(len(d)):
                row_cells[i].text = str(d[i])
            doc.add_paragraph()

        if row["ØªÙØ§ØµÙŠÙ„ Ø£ÙŠØ§Ù… Ø§Ù„ØºÙŠØ§Ø¨"]:
            doc.add_paragraph("ØªÙØ§ØµÙŠÙ„ Ø£ÙŠØ§Ù… Ø§Ù„ØºÙŠØ§Ø¨:")
            table = doc.add_table(rows=1, cols=1)
            table.style = 'Table Grid'
            table.rows[0].cells[0].text = "Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø§Ù„ÙŠÙˆÙ…)"
            for d in row["ØªÙØ§ØµÙŠÙ„ Ø£ÙŠØ§Ù… Ø§Ù„ØºÙŠØ§Ø¨"]:
                table.add_row().cells[0].text = d[0]
            doc.add_paragraph()

    output = BytesIO()
    doc.save(output)
    return output

# Streamlit app interface
st.title("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¶ÙˆØ± ÙˆØ¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Word")
uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF", type=["pdf"])
if uploaded_file is not None:
    raw_data = load_pdf_data(uploaded_file)
    df_summary = process_attendance_data(raw_data)
    if not df_summary.empty:
        word_output = export_to_word(df_summary)
        st.success("ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨Ù†Ø¬Ø§Ø­!")
        st.download_button("ğŸ“„ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Word", word_output.getvalue(), file_name="ØªÙ‚Ø±ÙŠØ±_Ø§Ù„Ø­Ø¶ÙˆØ±.docx")
    else:
        st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© Ù…Ù† Ø§Ù„Ù…Ù„Ù.")
