# Streamlit Web App to Analyze PDF Attendance and Export Word Report

import streamlit as st
import pandas as pd
import pdfplumber
from docx import Document
from datetime import datetime, timedelta
import calendar
from io import BytesIO

# --- Functions ---
def is_morning_shift(arrival_time): return 9 <= arrival_time.hour < 14
def is_evening_shift(arrival_time): return arrival_time.hour >= 14
def is_double_shift(arrival_time, departure_time): return arrival_time.hour < 14 and departure_time.hour >= 22
def is_single_punch_shift(punch_times): return len(punch_times) == 1
def count_shifts(shift_type): return 1 if shift_type in ['Ù…Ø³Ø§Ø¦ÙŠØ©', 'ØµØ¨Ø§Ø­ÙŠØ©', 'Ø¨ØµÙ…Ø© ÙˆØ§Ø­Ø¯Ø©'] else 2 if shift_type == 'Ù…Ø²Ø¯ÙˆØ¬Ø©' else 0
def calculate_overtime(total): return total - 26 if total > 26 else 0
def count_delays(punch_times): return len([p for p in punch_times if (p.hour == 15 and p.minute > 10) or (p.hour == 16)]), [p for p in punch_times if (p.hour == 15 and p.minute > 10) or (p.hour == 16)]

arabic_to_english_map = str.maketrans('Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©', '0123456789')
def convert_arabic_numerals(text): return text.translate(arabic_to_english_map) if isinstance(text, str) else text
def format_time_12h(time_obj): return time_obj.strftime("%I:%M %p")

def load_pdf_data(uploaded_file):
    data = []
    with pdfplumber.open(uploaded_file) as pdf:
        for page in pdf.pages:
            table = page.extract_table()
            if table and len(table) > 1:
                data.extend(table[1:])
    return data

def process_attendance_data(data):
    if not data:
        return pd.DataFrame()

    df = pd.DataFrame(data, columns=["Ø±Ù‚Ù… Ø§Ù„Ø¨ØµÙ…Ù‡", "Ø§Ù„Ø¥Ø³Ù…", "Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª"])
    df['cleaned'] = df['Ø§Ù„ØªØ§Ø±ÙŠØ®_Ø§Ù„ÙˆÙ‚Øª'].apply(convert_arabic_numerals)
    df['formatted'] = df['cleaned'].astype(str).str.replace('Ù…', 'PM').str.replace('Øµ', 'AM')
    df['datetime'] = pd.to_datetime(df['formatted'], format="%d/%m/%Y %I:%M %p", errors='coerce')
    df.dropna(subset=['datetime'], inplace=True)

    min_date = df['datetime'].min().date()
    max_date = df['datetime'].max().date()
    all_days = [min_date + timedelta(days=x) for x in range((max_date - min_date).days + 1)]

    summary = []

    for name, group in df.groupby("Ø§Ù„Ø¥Ø³Ù…"):
        group = group.sort_values('datetime')
        shifts_count = 0
        delays_count = 0
        shift_types = set()
        delay_details = []
        morning_shift_details = []
        late_departure_details = []
        attended_dates = set()
        double_shift_details = []

        for day, punches in group.groupby(group['datetime'].dt.date):
            punch_times = punches['datetime'].tolist()
            if not punch_times:
                continue

            attended_dates.add(day)
            arrival = min(punch_times)
            departure = max(punch_times)

            if is_single_punch_shift(punch_times):
                shift_type = 'Ø¨ØµÙ…Ø© ÙˆØ§Ø­Ø¯Ø©'
            elif is_double_shift(arrival, departure):
                shift_type = 'Ù…Ø²Ø¯ÙˆØ¬Ø©'
                duration = departure - arrival
                double_shift_details.append([str(day), format_time_12h(arrival), format_time_12h(departure), str(duration)])
            elif is_morning_shift(arrival):
                shift_type = 'ØµØ¨Ø§Ø­ÙŠØ©'
                morning_shift_details.append([str(day), format_time_12h(arrival), format_time_12h(departure)])
            elif is_evening_shift(arrival):
                shift_type = 'Ù…Ø³Ø§Ø¦ÙŠØ©'
            else:
                shift_type = 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'

            shifts_count += count_shifts(shift_type)
            shift_types.add(shift_type)
            daily_delays, delay_times = count_delays(punch_times)
            delays_count += daily_delays
            for delay_time in delay_times:
                delay_details.append([str(day), format_time_12h(delay_time)])

            if departure.hour > 22 or (departure.hour == 22 and departure.minute >= 20):
                late_departure_details.append([str(day), format_time_12h(departure)])

        overtime = calculate_overtime(shifts_count)
        absent_days = [d for d in all_days if d not in attended_dates]
        absent_days_formatted = [[f"{day.strftime('%Y-%m-%d')} ({calendar.day_name[day.weekday()]})"] for day in absent_days]

        summary.append({
            "Ø§Ù„Ø¥Ø³Ù…": name,
            "Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª": shifts_count,
            "Ù†ÙˆØ¹ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª": ', '.join(shift_types),
            "Ø¹Ø¯Ø¯ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª": delays_count,
            "ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª": delay_details,
            "Ø£ÙŠØ§Ù… Ø§Ù„ØºÙŠØ§Ø¨": len(absent_days),
            "ØªÙØ§ØµÙŠÙ„ Ø£ÙŠØ§Ù… Ø§Ù„ØºÙŠØ§Ø¨": absent_days_formatted,
            "Ø§Ù„Ø¯ÙˆØ§Ù… Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ": overtime,
            "ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„ØµØ¨Ø§Ø­ÙŠØ©": morning_shift_details,
            "ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„Ù…ØªØ£Ø®Ø±": late_departure_details,
            "ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©": double_shift_details
        })

    return pd.DataFrame(summary)

def export_to_word(summary_df):
    buffer = BytesIO()
    doc = Document()
    doc.add_heading("ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø­Ø¶ÙˆØ± ÙˆØ§Ù„Ø§Ù†ØµØ±Ø§Ù Ø§Ù„Ø¹Ø§Ù…", level=0)
    doc.add_paragraph("---")
    doc.add_paragraph()

    for _, row in summary_df.iterrows():
        doc.add_heading(f"Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¸Ù: {row['Ø§Ù„Ø¥Ø³Ù…']}", level=1)
        p = doc.add_paragraph()
        p.add_run(f"â€¢ Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª: {row['Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª']}\n")
        p.add_run(f"â€¢ Ù†ÙˆØ¹ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª: {row['Ù†ÙˆØ¹ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª']}\n")
        p.add_run(f"â€¢ Ø¹Ø¯Ø¯ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª: {row['Ø¹Ø¯Ø¯ Ø§Ù„ØªØ£Ø®ÙŠØ±Ø§Øª']}\n")
        p.add_run(f"â€¢ Ø£ÙŠØ§Ù… Ø§Ù„ØºÙŠØ§Ø¨: {row['Ø£ÙŠØ§Ù… Ø§Ù„ØºÙŠØ§Ø¨']}\n")
        p.add_run(f"â€¢ Ø§Ù„Ø¯ÙˆØ§Ù… Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ: {row['Ø§Ù„Ø¯ÙˆØ§Ù… Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ']}\n")

        if row["ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©"]:
            doc.add_paragraph("ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©:").bold = True
            table = doc.add_table(rows=1, cols=4)
            table.style = 'Table Grid'
            hdr_cells = table.rows[0].cells
            hdr_cells[0].text = 'Ø§Ù„ØªØ§Ø±ÙŠØ®'
            hdr_cells[1].text = 'ÙˆÙ‚Øª Ø§Ù„Ø­Ø¶ÙˆØ±'
            hdr_cells[2].text = 'ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØµØ±Ø§Ù'
            hdr_cells[3].text = 'Ø§Ù„Ù…Ø¯Ø©'
            for d in row["ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ±Ø¯ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©"]:
                cells = table.add_row().cells
                cells[0].text, cells[1].text, cells[2].text, cells[3].text = d

        doc.add_paragraph("=" * 60)
        doc.add_paragraph()

    doc.save(buffer)
    buffer.seek(0)
    return buffer

# --- Streamlit Interface ---
st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¶ÙˆØ±", layout="centered")
st.title("ğŸ“„ Ø£Ø¯Ø§Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¶ÙˆØ± ÙˆØ¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Word")
uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø¶ÙˆØ±", type="pdf")

if uploaded_file:
    with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
        data = load_pdf_data(uploaded_file)
        summary_df = process_attendance_data(data)

    if summary_df.empty:
        st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„.")
    else:
        st.success("âœ… ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­! ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø£Ø¯Ù†Ø§Ù‡.")
        word_buffer = export_to_word(summary_df)
        st.download_button(
            label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Word",
            data=word_buffer,
            file_name="ØªÙ‚Ø±ÙŠØ±_Ø§Ù„Ø­Ø¶ÙˆØ±.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
